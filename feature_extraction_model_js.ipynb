{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Feature Extraction and Modeling"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# General Setup"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# import torchvision.models as models\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import sklearn.model_selection as model_selection\n",
    "import sklearn.linear_model as linear_model\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    precision_score,\n",
    "    f1_score,\n",
    "    recall_score,\n",
    ")\n",
    "\n",
    "from methods import (\n",
    "    get_labels, load_image, create_histogram, calculate_glcm_features, apply_gabor_filters_and_extract_features, ImageHeuristicFeatureExtractor, standardize_features,\n",
    "    ImageDataset,\n",
    "    merge_features_with_labels,\n",
    "    not_oversampled_images,\n",
    "    calculate_test_size,\n",
    "    calculate_metrics,\n",
    "    plot_confusion_matrix,\n",
    "    plot_low_dim_components,)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.manifold import TSNE\n",
    "import shap\n",
    "\n",
    "import cv2\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": ""
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# load repo and\n",
    "repo_dir = (\n",
    "    subprocess.Popen([\"git\", \"rev-parse\", \"--show-toplevel\"], stdout=subprocess.PIPE)\n",
    "    .communicate()[0]\n",
    "    .rstrip()\n",
    "    .decode(\"utf-8\")\n",
    ")\n",
    "#original_folder_path = os.path.join(repo_dir, \"dataverse_files/HAM10000_images_part_1\")\n",
    "# original_folder_path =  os.path.join(repo_dir, 'dataverse_files/HAM10000_images_part_1_2')\n",
    "original_folder_path = os.path.join(repo_dir, \"dataverse_files/JS_Selection\")\n",
    "\n",
    "processed_folder_path = os.path.join(repo_dir, \"preprocessed_images\")\n",
    "#processed_folder_path = os.path.join(repo_dir, \"preprocessed_images_10k_rotated\")\n",
    "features_folder_path = os.path.join(repo_dir, \"features_extracted\")\n",
    "\n",
    "os.makedirs(processed_folder_path, exist_ok=True)\n",
    "os.makedirs(features_folder_path, exist_ok=True)\n",
    "\n",
    "data_folder_path = original_folder_path\n",
    "\n",
    "label = get_labels(repo_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Feature Extraction"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Feature Exctraction using ResNet50 (CNN)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Using the RestNet 50 model to extract features using pretrained weights\n",
    "model = resnet50(weights=ResNet50_Weights.DEFAULT)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(232),\n",
    "        transforms.CenterCrop(450),  # adapted to use larger region\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "dataset = ImageDataset(directory=data_folder_path, transform=transform)\n",
    "data_loader = DataLoader(dataset, batch_size=16, shuffle=False, num_workers=0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Determine the best available device\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model = model.to(device)  # Move your model to the appropriate device\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "features_map2 = {}\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (key, images) in enumerate(tqdm(data_loader)):\n",
    "        images = images.to(device)  # Move images to the appropriate device\n",
    "\n",
    "        batch_features = model(images)\n",
    "        batch_features = batch_features.view(\n",
    "            batch_features.size(0), -1\n",
    "        )  # Flatten features\n",
    "\n",
    "        batch_features = (\n",
    "            batch_features.cpu().numpy()\n",
    "        )  # Move features to CPU for numpy conversion\n",
    "\n",
    "        for i, feature in enumerate(batch_features):\n",
    "            image_id = (\n",
    "                    batch_idx * data_loader.batch_size + i\n",
    "            )  # Compute global image ID/index\n",
    "            features_map2[key[i]] = feature\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Saving the raw features\n",
    "features_df = pd.DataFrame(features_map2)\n",
    "cnn_features_path = os.path.join(features_folder_path, \"features.json\")\n",
    "features_df.to_json(cnn_features_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load CNN Features (also previously generated)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# load features + combine the features with labels dataframe\n",
    "features_path = os.path.join(features_folder_path, \"features.json\")\n",
    "cnn_features = merge_features_with_labels(\n",
    "    features_path=features_path,\n",
    "    labels_df=label,\n",
    "    export=True,\n",
    ")\n",
    "cnn_features"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Heuristic Feature Extraction\n",
    "Attention! The order of the features using the CNN and this Class is not necessarily the same!"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "extractor = ImageHeuristicFeatureExtractor(data_folder_path, label.set_index(\"image_id\"))\n",
    "\n",
    "feature_label_data = extractor.get_feature_and_label_arrays()\n",
    "df_heuristic = extractor.return_one_df()  # effectively dummy df with the filenames and image ids\n",
    "\n",
    "x_rgb, y_rgb = feature_label_data['rgb']\n",
    "x_hsv, y_hsv = feature_label_data['hsv']\n",
    "x_glcm, y_glcm = feature_label_data['glcm']\n",
    "# x_gabor, y_gabor = feature_label_data['gabor']\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x_rgb_standardized = standardize_features(x_rgb, use_pca=True, n_components=0.9)\n",
    "x_hsv_stanardized = standardize_features(x_hsv, use_pca=True, n_components=0.9)\n",
    "\n",
    "x_heuristic = np.concatenate(\n",
    "    (x_rgb_standardized,\n",
    "     x_hsv_stanardized,\n",
    "    x_glcm), axis=1)\n",
    "y_heuristic = y_hsv\n",
    "np.shape(x_heuristic)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "names_heuristic_features = []\n",
    "\n",
    "for i in range(len(x_rgb_standardized[0])):\n",
    "    names_heuristic_features.append(f\"rgb{i}\")\n",
    "\n",
    "for i in range(len(x_hsv_stanardized[0])):\n",
    "    names_heuristic_features.append(f\"hsv{i}\")\n",
    "\n",
    "for i in range(len(x_glcm[0])):\n",
    "    names_heuristic_features.append(f\"glcm{i}\")\n",
    "\n",
    "len(names_heuristic_features)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "np.save(os.path.join(features_folder_path, \"x_heuristic\"), x_heuristic)\n",
    "np.save(os.path.join(features_folder_path, \"y_heuristic\"), y_heuristic)\n",
    "np.save(os.path.join(features_folder_path, \"names_heuristic_features\"), names_heuristic_features)\n",
    "df_heuristic.to_csv(os.path.join(features_folder_path, \"df_heuristic\"), index=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x_heuristic = np.load(os.path.join(features_folder_path, \"x_heuristic.npy\"))\n",
    "y_heuristic = np.load(os.path.join(features_folder_path, \"y_heuristic.npy\"))\n",
    "names_heuristic_features = np.load(os.path.join(features_folder_path, \"names_heuristic_features.npy\"))\n",
    "df_heuristic = pd.read_csv(os.path.join(features_folder_path, \"df_heuristic\"), index_col=0)\n",
    "df_heuristic"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Modeling"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Generate the Train and Test Split"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define which x and y to use\n",
    "\n",
    "# CNN:\n",
    "x = cnn_features.iloc[:, :1000].to_numpy()\n",
    "y = cnn_features[\"cancer\"].to_numpy()\n",
    "df_ = cnn_features\n",
    "\n",
    "# Heuristic\n",
    "\"\"\"\n",
    "x = x_heuristic\n",
    "y = y_heuristic\n",
    "df_ = df_heuristic\n",
    "np.shape(x)\n",
    "\"\"\"\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# only include those files in testing that have not been oversampled\n",
    "include_in_testing = not_oversampled_images(df_)\n",
    "\n",
    "TEST_SIZE = 0.30\n",
    "\n",
    "# Calculate the adjusted test size\n",
    "test_size_sklearn = calculate_test_size(df_, TEST_SIZE, include_in_testing)\n",
    "\n",
    "x_train_, x_test, y_train_, y_test = model_selection.train_test_split(\n",
    "    x[include_in_testing], y[include_in_testing], test_size=test_size_sklearn\n",
    ")\n",
    "x_train = np.concatenate((x_train_, x[np.invert(include_in_testing)]), axis=0)\n",
    "y_train = np.concatenate((y_train_, y[np.invert(include_in_testing)]), axis=0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "np.shape(x_train), np.shape(y_train), np.shape(x_test), np.shape(y_test), len(\n",
    "    x_test\n",
    ") / len(x), len(np.unique(df_.image_id))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Dimensionality Reduction\n",
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Initialize PCA,\n",
    "pca = PCA(n_components=0.999)\n",
    "\n",
    "# Fit and transform the data\n",
    "pca.fit(np.concatenate((x_train, x_test), axis=0))\n",
    "x_train_pca = pca.transform(x_train)\n",
    "x_test_pca = pca.transform(x_test)\n",
    "\n",
    "# Check the new shape of the data\n",
    "print(x_train_pca.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "plot_low_dim_components(x_train_pca, y_train, component_1=0, component_2=1)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Kernel PCA (slow)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize PCA,\n",
    "kpca = KernelPCA(n_components=25, kernel=\"rbf\")  # kernel: rbf, sigmoid\n",
    "\n",
    "# Fit and transform the data\n",
    "kpca.fit(np.concatenate((x_train, x_test), axis=0))\n",
    "x_train_kpca = kpca.transform(x_train)\n",
    "x_test_kpca = kpca.transform(x_test)\n",
    "\n",
    "# Check the new shape of the data\n",
    "print(x_train_kpca.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_low_dim_components(x_train_kpca, y_train, label=\"kPCA\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### t-SNE (Visualisation *only*)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set the parameters for t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=0, perplexity=15, n_iter=2000, verbose=1)\n",
    "\n",
    "# Perform t-SNE on the data\n",
    "X_tsne = tsne.fit_transform(np.concatenate((x_train, x_test), axis=0))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plot_low_dim_components(\n",
    "    X_tsne, np.concatenate((y_train, y_test), axis=0), label=\"t-SNE\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Use Lower Dimensional Features?"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x_train = x_train  # x_train #x_train_kpca #x_train_pca\n",
    "x_test = x_test  # x_test #x_test_kpca#x_test_pca"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## LogisticRegression"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "prediction_model = linear_model.LogisticRegression(\n",
    "    solver=\"newton-cg\", multi_class=\"auto\", max_iter=5000, class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "prediction_model.fit(x_train, y_train)\n",
    "\n",
    "y_train_pred = prediction_model.predict(x_train)\n",
    "y_pred = prediction_model.predict(x_test)\n",
    "# plot_confusion_matrix(y_train, y_train_pred)\n",
    "plot_confusion_matrix(y_test, y_pred)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## SVM"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(x_train)\n",
    "X_test = scaler.transform(x_test)\n",
    "\n",
    "# Create an SVM classifier\n",
    "prediction_model = svm.SVC(kernel=\"poly\", C=1.0, gamma=0.5, class_weight=\"balanced\", )\n",
    "\n",
    "# Train the classifier\n",
    "prediction_model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = prediction_model.predict(x_test)\n",
    "plot_confusion_matrix(y_test, y_pred)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## SHAP Values\n",
    "Not too sure how helpful this is. But we can can see how much individual features are influencing the result"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create the SHAP Explainer\n",
    "\n",
    "# Without names\n",
    "explainer = shap.Explainer(prediction_model.predict, x_train, max_evals=2500, verbose=1)\n",
    "\n",
    "# With names (only defined for heuristic model)\n",
    "#explainer = shap.Explainer(prediction_model.predict, x_train, max_evals=2500, verbose=1, feature_names=names_heuristic_features)\n",
    "\n",
    "shap_values = explainer(x_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = plt.figure()\n",
    "shap.summary_plot(shap_values, x_test)\n",
    "\n",
    "# Save the current figure\n",
    "save_path = os.path.join(features_folder_path, \"shap_values.png\")\n",
    "fig.savefig(save_path, dpi=150, bbox_inches='tight')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
