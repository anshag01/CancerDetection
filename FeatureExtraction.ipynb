{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Feature Extraction using RestNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import methods \n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the RestNet 50 model to extract features\n",
    "model = models.resnet50(pretrained = True)\n",
    "feature_extractor = torch.nn.Sequential(*list(model.children())[:-1])\n",
    "feature_extractor.eval()\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data PreProcessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, directory, transform=None):\n",
    "        self.directory = directory\n",
    "        self.transform = transform\n",
    "        self.images = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith((\".jpg\", \".png\"))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #Do preprocessing here \n",
    "        image_path = self.images[idx]\n",
    "        rgb_image_arr = methods.convert_rgb(image_path)\n",
    "        normalised_img = methods.z_normalization(rgb_image_arr)\n",
    "        image = Image.fromarray(normalised_img.astype('uint8'), 'RGB')\n",
    "        image_tensor = self.transform(image) if self.transform else image\n",
    "        key = os.path.basename(image_path).removesuffix('.jpg').removesuffix('.png')\n",
    "        return key, image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_folder_path =  '../dataverse_files/HAM10000_images_part_1'\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "dataset = ImageDataset(directory=original_folder_path, transform=transform)\n",
    "data_loader = DataLoader(dataset, batch_size=16, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting features\n",
    "features_map2 = {}\n",
    "with torch.no_grad():\n",
    "    for batch_idx, output in enumerate(data_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images = images.cuda()\n",
    "\n",
    "        \n",
    "        key, images = output\n",
    "        batch_features = model(images) \n",
    "        #print(batch_features.shape)\n",
    "        batch_features = batch_features.view(batch_features.size(0), -1)  # Flatten features\n",
    "              \n",
    "        batch_features = batch_features.cpu().numpy()\n",
    "        \n",
    "        for i, feature in enumerate(batch_features):\n",
    "            image_id = batch_idx * data_loader.batch_size + i  # Compute global image ID/index\n",
    "            features_map2[key[i]] = feature\n",
    "            print(f'Done for image {image_id}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the features\n",
    "features_df = pd.DataFrame(features_map2)\n",
    "features_df\n",
    "features_df.to_json('features.json')\n",
    "features_df\n",
    "#np.save('features.npy', features_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
