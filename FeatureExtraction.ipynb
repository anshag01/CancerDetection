{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Feature Extraction using RestNet"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import methods \n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import sklearn.model_selection as model_selection\n",
    "import sklearn.linear_model as linear_model\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn import linear_model, metrics, model_selection\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from methods import *"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#Using the RestNet 50 model to extract features\n",
    "model = models.resnet50(pretrained = True)\n",
    "feature_extractor = torch.nn.Sequential(*list(model.children())[:-1])\n",
    "feature_extractor.eval()\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data PreProcessing "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, directory, transform=None):\n",
    "        self.directory = directory\n",
    "        self.transform = transform\n",
    "        self.images = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith((\".jpg\", \".png\"))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #Do preprocessing here \n",
    "        image_path = self.images[idx]\n",
    "        rgb_image_arr = methods.convert_rgb(image_path)\n",
    "        normalised_img = methods.z_normalization(rgb_image_arr)\n",
    "        image = Image.fromarray(normalised_img.astype('uint8'), 'RGB')\n",
    "        image_tensor = self.transform(image) if self.transform else image\n",
    "        key = os.path.basename(image_path).removesuffix('.jpg').removesuffix('.png')\n",
    "        return key, image_tensor"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "original_folder_path =  '../dataverse_files/HAM10000_images_train'\n",
    "lst_folders = [original_folder_path]\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "data_loaders = []\n",
    "for original_folder_path in lst_folders:\n",
    "    dataset = ImageDataset(directory=original_folder_path, transform=transform)\n",
    "    data_loader = DataLoader(dataset, batch_size=16, shuffle=False, num_workers=0)\n",
    "    data_loaders.append(data_loader)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if os.path.exists('features.json'):\n",
    "    features_map2 = methods.load_features('features.json').T\n",
    "else:\n",
    "    #Extracting features\n",
    "    features_map2 = {}\n",
    "    with torch.no_grad():\n",
    "        for data_loader in data_loaders:\n",
    "            for batch_idx, output in enumerate(data_loader):\n",
    "                if torch.cuda.is_available():\n",
    "                    images = images.cuda()\n",
    "\n",
    "                \n",
    "                key, images = output\n",
    "                batch_features = model(images) \n",
    "                batch_features = batch_features.view(batch_features.size(0), -1)  # Flatten features\n",
    "                    \n",
    "                batch_features = batch_features.cpu().numpy()\n",
    "                \n",
    "                for i, feature in enumerate(batch_features):\n",
    "                    image_id = batch_idx * data_loader.batch_size + i  # Compute global image ID/index\n",
    "                    features_map2[key[i]] = feature\n",
    "                    print(f'Done for image {image_id}')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Dataframe For Prediction"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "labels_df = pd.read_csv('../dataverse_files/HAM10000_metadata.csv')\n",
    "final_label = pd.DataFrame(labels_df['result'])\n",
    "final_label.index = labels_df['image_id']\n",
    "merged_data = methods.merge_features_with_labels('features.json', final_label)\n",
    "merged_data.index = merged_data['image_id']\n",
    "merged_data"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Prediction using Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#Get the columns that is not equal to result\n",
    "X = merged_data.loc[:, ~(merged_data.columns.isin(['result', 'image_id', 'filename']))].copy()\n",
    "y = merged_data['result'].copy()\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = linear_model.LogisticRegression(solver='newton-cg', multi_class='auto', max_iter=5000)\n",
    "y_pred = model.fit(X_train, y_train).predict(X_test)\n",
    "methods.plot_confusion_matrix(y_test,y_pred,True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction using Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn import svm\n",
    "X = merged_data.loc[:, ~(merged_data.columns.isin(['result', 'image_id', 'filename']))].copy()\n",
    "y = merged_data['result'].copy()\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = svm.SVC(kernel='linear').fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "methods.plot_confusion_matrix(y_test,y_pred,True)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Using Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "model = MLPClassifier(hidden_layer_sizes = [400]*4, \n",
    "                      random_state = 1)\n",
    "X = merged_data.loc[:, ~(merged_data.columns.isin(['result', 'image_id', 'filename']))].copy()\n",
    "y = merged_data['result'].copy()\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "methods.plot_confusion_matrix(y_test,y_pred,True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Using RestNet"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model = models.resnet50(pretrained = True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "num_classes = 2\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup DataLoaders"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Criterion and Scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    " #Criterion (Loss function)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer (Only train the final layer)\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "# Learning rate scheduler (optional)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df_img_labels = pd.DataFrame(merged_data[['image_id', 'result']])\n",
    "df_img_labels['result'] = df_img_labels['result'].apply(lambda x: 1 if x == 1 else 0)\n",
    "df_img_labels\n",
    "#0 is non-cancerous and 1 is cancerous"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, img_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe (DataFrame): DataFrame containing image IDs and labels.\n",
    "            img_dir (str): Directory where images are stored.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.img_labels = dataframe\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.img_labels.iloc[idx, 0]\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0] + '.jpg')  # Assuming images are .jpg\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "original_folder_path =  '../dataverse_files/HAM10000_images_part_1_2'\n",
    "transform =  transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "dataset = CustomImageDataset(dataframe=df_img_labels, img_dir=original_folder_path, transform=transform)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from torch.utils.data import random_split\n",
    "total_size = len(dataset)\n",
    "test_size = int(0.2 * total_size)\n",
    "train_size = total_size - test_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 10  # Set the number of epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    train_loss = 0.0\n",
    "    train_corrects = 0\n",
    "\n",
    "    # Training loop\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Statistics\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        train_corrects += torch.sum(preds == labels.data)\n",
    "        #print(f'Loss: {loss.item()}')\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_acc = train_corrects.float() / len(train_loader.dataset)\n",
    "\n",
    "    # Print training results\n",
    "    print(f'Epoch {epoch+1}/{num_epochs} - Loss: {train_loss:.4f}, Acc: {train_acc:.4f}')\n",
    "\n",
    "    # Evaluation loop\n",
    "model.eval()  # Set model to evaluate mode\n",
    "all_test_preds = []\n",
    "all_test_labels = []\n",
    "test_loss = 0.0\n",
    "test_corrects = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_test_preds.extend(preds.cpu().numpy())\n",
    "        all_test_labels.extend(labels.cpu().numpy())\n",
    "        # Statistics\n",
    "        test_loss += loss.item() * inputs.size(0)\n",
    "        test_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "test_loss /= len(test_loader.dataset)\n",
    "test_acc = test_corrects.float() / len(test_loader.dataset)\n",
    "\n",
    "# Print test results\n",
    "#Plot the confusion matrix\n",
    "methods.plot_confusion_matrix(all_test_labels,all_test_preds,True)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
