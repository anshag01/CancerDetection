{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Feature Extraction and Modeling"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# General Setup"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import sklearn.model_selection as model_selection\n",
    "import sklearn.linear_model as linear_model\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from methods import (\n",
    "    get_labels,\n",
    "    ImageHeuristicFeatureExtractor,\n",
    "    standardize_features,\n",
    "    ImageDataset,\n",
    "    merge_features_with_labels,\n",
    "    not_oversampled_images,\n",
    "    calculate_test_size,\n",
    "    plot_confusion_matrix,\n",
    "    plot_low_dim_components,\n",
    ")\n",
    "\n",
    "from data_augmentation import split_data_and_oversample\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import shap\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# load repo and\n",
    "repo_dir = (\n",
    "    subprocess.Popen([\"git\", \"rev-parse\", \"--show-toplevel\"], stdout=subprocess.PIPE)\n",
    "    .communicate()[0]\n",
    "    .rstrip()\n",
    "    .decode(\"utf-8\")\n",
    ")\n",
    "\n",
    "# Set the folder containing the raw images\n",
    "original_folder_path = os.path.join(\n",
    "    repo_dir, \"dataverse_files/HAM10000_images_part_1_2_3\"\n",
    ")\n",
    "\n",
    "# Create Folders\n",
    "features_folder_path = os.path.join(repo_dir, \"features_extracted\")\n",
    "processed_folder_path = os.path.join(repo_dir, \"preprocessed_images\")\n",
    "figures_folder_path = os.path.join(repo_dir, \"figures\")\n",
    "os.makedirs(processed_folder_path, exist_ok=True)\n",
    "os.makedirs(features_folder_path, exist_ok=True)\n",
    "os.makedirs(figures_folder_path, exist_ok=True)\n",
    "\n",
    "# get pandas dataframe\n",
    "label = get_labels(repo_dir)\n",
    "\n",
    "# Load old features (or write new features using this name)\n",
    "cnn_features_path = os.path.join(features_folder_path, \"features.json\")\n",
    "\n",
    "TRAIN_SIZE = 0.8\n",
    "OVERSAMPLE = False  #  if set to false will not oversample the minority class\n",
    "\n",
    "if \"oversampled\" in cnn_features_path and OVERSAMPLE:\n",
    "    data_folder_path = processed_folder_path\n",
    "else:\n",
    "    data_folder_path = original_folder_path"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Oversampling"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if OVERSAMPLE:\n",
    "    if not os.listdir(data_folder_path):\n",
    "        try:\n",
    "            split_data_and_oversample(\n",
    "                original_folder_path,\n",
    "                processed_folder_path,\n",
    "                label,\n",
    "                TRAIN_SIZE,\n",
    "                oversample=OVERSAMPLE,\n",
    "                move_picture_up_levels=2,\n",
    "            )\n",
    "        except OSError as e:\n",
    "            print(e)\n",
    "            assert False, \"delete the Folder 'preprocessed_images' and try again\"\n",
    "    else:\n",
    "        print(f\"Used pre-processed features at {data_folder_path}\")\n",
    "else:\n",
    "    print(\"No Oversampling\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Feature Extraction"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## (A) Feature Exctraction using ResNet50 (CNN)"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Using the RestNet 50 model to extract features using pretrained weights\n",
    "model = resnet50(weights=ResNet50_Weights.DEFAULT)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(232),\n",
    "        transforms.CenterCrop(450),  # adapted to use larger region\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "dataset = ImageDataset(directory=data_folder_path, transform=transform)\n",
    "data_loader = DataLoader(dataset, batch_size=16, shuffle=False, num_workers=0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Determine the best available device\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if not os.path.exists(cnn_features_path):\n",
    "    model = model.to(device)  # Move your model to the appropriate device\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    features_map2 = {}\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (key, images) in enumerate(tqdm(data_loader)):\n",
    "            images = images.to(device)  # Move images to the appropriate device\n",
    "\n",
    "            batch_features = model(images)\n",
    "            batch_features = batch_features.view(\n",
    "                batch_features.size(0), -1\n",
    "            )  # Flatten features\n",
    "\n",
    "            batch_features = (\n",
    "                batch_features.cpu().numpy()\n",
    "            )  # Move features to CPU for numpy conversion\n",
    "\n",
    "            for i, feature in enumerate(batch_features):\n",
    "                image_id = (\n",
    "                    batch_idx * data_loader.batch_size + i\n",
    "                )  # Compute global image ID/index\n",
    "                features_map2[key[i]] = feature\n",
    "\n",
    "    # Saving the raw features\n",
    "    features_df = pd.DataFrame(features_map2)\n",
    "    features_df.to_json(cnn_features_path)\n",
    "else:\n",
    "    print(f\"Previously computed features used: {cnn_features_path}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Load CNN Features (also previously generated)"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# load features + combine the features with labels dataframe\n",
    "cnn_features = merge_features_with_labels(\n",
    "    features_path=cnn_features_path,\n",
    "    labels_df=label,\n",
    "    export=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (B) Heuristic Feature Extraction\n",
    "Attention! The order of the features using the CNN and this Class is not necessarily the same!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "extractor = ImageHeuristicFeatureExtractor(\n",
    "    data_folder_path, label.set_index(\"image_id\")\n",
    ")\n",
    "\n",
    "feature_label_data = extractor.get_feature_and_label_arrays()\n",
    "df_heuristic = (\n",
    "    extractor.return_one_df()\n",
    ")  # effectively dummy df with the filenames and image ids\n",
    "\n",
    "x_rgb, y_rgb = feature_label_data[\"rgb\"]\n",
    "x_hsv, y_hsv = feature_label_data[\"hsv\"]\n",
    "x_glcm, y_glcm = feature_label_data[\"glcm\"]\n",
    "# x_gabor, y_gabor = feature_label_data['gabor']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "x_rgb_standardized = standardize_features(x_rgb, use_pca=True, n_components=0.9)\n",
    "x_hsv_stanardized = standardize_features(x_hsv, use_pca=True, n_components=0.9)\n",
    "\n",
    "x_heuristic = np.concatenate((x_rgb_standardized, x_hsv_stanardized, x_glcm), axis=1)\n",
    "y_heuristic = y_hsv\n",
    "np.shape(x_heuristic)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "names_heuristic_features = []\n",
    "\n",
    "for i in range(len(x_rgb_standardized[0])):\n",
    "    names_heuristic_features.append(f\"rgb{i}\")\n",
    "\n",
    "for i in range(len(x_hsv_stanardized[0])):\n",
    "    names_heuristic_features.append(f\"hsv{i}\")\n",
    "\n",
    "for i in range(len(x_glcm[0])):\n",
    "    names_heuristic_features.append(f\"glcm{i}\")\n",
    "\n",
    "len(names_heuristic_features)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Modeling"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Generate the Train and Test Split"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Define which x and y to use (either run part (A) or (B)\n",
    "\n",
    "# Heuristic\n",
    "\"\"\"\n",
    "x = x_heuristic\n",
    "y = y_heuristic\n",
    "df_ = df_heuristic\n",
    "np.shape(x)\n",
    "\"\"\"\n",
    "\n",
    "# CNN:\n",
    "x = cnn_features.iloc[:, :1000].to_numpy()\n",
    "y = cnn_features[\"cancer\"].to_numpy()\n",
    "df_ = cnn_features"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# only include those files in testing that have not been oversampled\n",
    "include_in_testing = not_oversampled_images(df_)\n",
    "\n",
    "TEST_SIZE = 0.20\n",
    "\n",
    "# Calculate the adjusted test size\n",
    "test_size_sklearn = calculate_test_size(df_, TEST_SIZE, include_in_testing)\n",
    "\n",
    "x_train_, x_test, y_train_, y_test = model_selection.train_test_split(\n",
    "    x[include_in_testing],\n",
    "    y[include_in_testing],\n",
    "    test_size=test_size_sklearn,\n",
    "    random_state=42,\n",
    ")\n",
    "x_train = np.concatenate((x_train_, x[np.invert(include_in_testing)]), axis=0)\n",
    "y_train = np.concatenate((y_train_, y[np.invert(include_in_testing)]), axis=0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\n",
    "    f\"{len(y_test)} Unique Images used Test Set: {len(y_test) / len(np.unique(df_.image_id)) * 100:.2f}%\"\n",
    ")\n",
    "print(f\"{len(y_train)} Non-Unique Images used Train Set\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction\n",
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Initialize PCA,\n",
    "pca = PCA(n_components=0.999)\n",
    "\n",
    "# Fit and transform the data\n",
    "pca.fit(np.concatenate((x_train, x_test), axis=0))\n",
    "x_train_pca = pca.transform(x_train)\n",
    "x_test_pca = pca.transform(x_test)\n",
    "\n",
    "# Check the new shape of the data\n",
    "print(x_train_pca.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plot_low_dim_components(x_train_pca, y_train, component_1=0, component_2=1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Kernel PCA (slow)"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Initialize PCA,\n",
    "kpca = KernelPCA(n_components=25, kernel=\"rbf\")  # kernel: rbf, sigmoid\n",
    "\n",
    "# Fit and transform the data\n",
    "kpca.fit(np.concatenate((x_train, x_test), axis=0))\n",
    "x_train_kpca = kpca.transform(x_train)\n",
    "x_test_kpca = kpca.transform(x_test)\n",
    "\n",
    "# Check the new shape of the data\n",
    "print(x_train_kpca.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plot_low_dim_components(x_train_kpca, y_train, label=\"kPCA\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### t-SNE (Visualisation *only*)"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Set the parameters for t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=0, perplexity=30, n_iter=2000, verbose=1)\n",
    "\n",
    "# Perform t-SNE on the data\n",
    "X_tsne = tsne.fit_transform(np.concatenate((x_train, x_test), axis=0))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plot_low_dim_components(\n",
    "    X_tsne, np.concatenate((y_train, y_test), axis=0), label=\"t-SNE\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Use Lower Dimensional Features?"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "x_train = x_train  # x_train #x_train_kpca #x_train_pca\n",
    "x_test = x_test  # x_test #x_test_kpca#x_test_pca"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## LogisticRegression"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "prediction_model = linear_model.LogisticRegression(\n",
    "    solver=\"newton-cg\",\n",
    "    multi_class=\"auto\",\n",
    "    max_iter=10000,\n",
    "    class_weight=\"balanced\",\n",
    ")\n",
    "\n",
    "prediction_model.fit(x_train, y_train)\n",
    "\n",
    "y_train_pred = prediction_model.predict(x_train)\n",
    "y_pred = prediction_model.predict(x_test)\n",
    "\n",
    "cf = plot_confusion_matrix(y_test, y_pred, return_fig=True)\n",
    "fig = cf.figure_\n",
    "plt.gca().set_title(\"Logistic Regression\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(figures_folder_path + \"/log_regression.pdf\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## SVM"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(x_train)\n",
    "X_test = scaler.transform(x_test)\n",
    "\n",
    "# Create an SVM classifier\n",
    "prediction_model = svm.SVC(\n",
    "    kernel=\"poly\",\n",
    "    C=1.0,\n",
    "    gamma=0.5,\n",
    "    class_weight=\"balanced\",\n",
    ")\n",
    "\n",
    "# Train the classifier\n",
    "prediction_model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = prediction_model.predict(x_test)\n",
    "\n",
    "cf = plot_confusion_matrix(y_test, y_pred, return_fig=True)\n",
    "fig = cf.figure_\n",
    "plt.gca().set_title(\"SVM\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(figures_folder_path + \"/svm.pdf\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## MLPClassifier"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# solvers = [\"lbfgs\", \"sgd\", \"adam\"]\n",
    "prediction_model = MLPClassifier(\n",
    "    hidden_layer_sizes=[400] * 4,\n",
    "    random_state=1,\n",
    "    verbose=0,\n",
    "    solver=\"adam\",\n",
    "    # learning_rate=\"adaptive\",\n",
    ")\n",
    "prediction_model.fit(x_train, y_train)\n",
    "y_pred = prediction_model.predict(x_test)\n",
    "\n",
    "cf = plot_confusion_matrix(y_test, y_pred, return_fig=True)\n",
    "fig = cf.figure_\n",
    "plt.gca().set_title(\"MLP\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(figures_folder_path + \"/mlp.pdf\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## AdaBoost Classifer  "
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "estimator = DecisionTreeClassifier(max_depth=3)\n",
    "adaboost_model = AdaBoostClassifier(\n",
    "    estimator=estimator, n_estimators=500, algorithm=\"SAMME\", random_state=0\n",
    ")\n",
    "adaboost_model.fit(x_train, y_train)\n",
    "y_pred = adaboost_model.predict(x_test)\n",
    "\n",
    "cf = plot_confusion_matrix(y_test, y_pred, return_fig=True)\n",
    "fig = cf.figure_\n",
    "plt.gca().set_title(\"AdaBoost\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(figures_folder_path + \"/adaboost.pdf\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP Values\n",
    "We can see how much individual features are influencing the result! Especially useful for the heuristic features"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create the SHAP Explainer\n",
    "\n",
    "# With names (only defined for heuristic features)\n",
    "\"\"\"\n",
    "explainer = shap.Explainer(\n",
    "    prediction_model.predict,\n",
    "    x_train,\n",
    "    max_evals=4000,\n",
    "    verbose=1,\n",
    "    feature_names=names_heuristic_features,\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# Without names (CNN features)\n",
    "explainer = shap.Explainer(prediction_model.predict, x_train, max_evals=2500, verbose=1)\n",
    "\n",
    "shap_values = explainer(x_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig = plt.figure()\n",
    "shap.summary_plot(shap_values, x_test, max_display=6)\n",
    "\n",
    "# Save the current figure\n",
    "save_path = os.path.join(figures_folder_path, \"shap_values.pdf\")\n",
    "fig.savefig(figures_folder_path + \"/shap.pdf\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# End to End RestNet(Training and Testing)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Setup"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_classes = 2\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Setup DataLoader"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Criterion (Loss function)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer (Only train the final layer)\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "# Learning rate scheduler (optional)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df_img_labels = pd.DataFrame(label[[\"image_id\", \"cancer\"]])\n",
    "df_img_labels[\"result\"] = df_img_labels[\"cancer\"].apply(\n",
    "    lambda x: 0 if x is False else 1\n",
    ")\n",
    "\n",
    "# Select only the images that are in the data folder\n",
    "df_img_labels = df_img_labels[\n",
    "    df_img_labels.image_id.isin(\n",
    "        [x.split(\".\")[-2] for x in os.listdir(data_folder_path)]\n",
    "    )\n",
    "]\n",
    "df_img_labels"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, img_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe (DataFrame): DataFrame containing image IDs and labels.\n",
    "            img_dir (str): Directory where images are stored.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.img_labels = dataframe\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        self.img_labels.iloc[idx, 0]\n",
    "        img_path = os.path.join(\n",
    "            self.img_dir, self.img_labels.iloc[idx, 0] + \".jpg\"\n",
    "        )  # Assuming images are .jpg\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "original_folder_path = data_folder_path\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(232),\n",
    "        transforms.CenterCrop(450),  # adapted to use larger region\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "dataset = CustomImageDataset(\n",
    "    dataframe=df_img_labels, img_dir=original_folder_path, transform=transform\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Splitting Data"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "total_size = len(dataset)\n",
    "test_size = int(0.2 * total_size)\n",
    "train_size = total_size - test_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Training and Testing"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 10  # Set the number of epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    train_loss = 0.0\n",
    "    train_corrects = 0\n",
    "\n",
    "    # Training loop\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Statistics\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        train_corrects += torch.sum(preds == labels.data)\n",
    "        # print(f'Loss: {loss.item()}')\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_acc = train_corrects.float() / len(train_loader.dataset)\n",
    "\n",
    "    # Print training results\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{num_epochs} - Loss: {train_loss:.4f}, Acc: {train_acc:.4f}\"\n",
    "    )\n",
    "\n",
    "    # Evaluation loop\n",
    "model.eval()  # Set model to evaluate mode\n",
    "all_test_preds = []\n",
    "all_test_labels = []\n",
    "test_loss = 0.0\n",
    "test_corrects = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_test_preds.extend(preds.cpu().numpy())\n",
    "        all_test_labels.extend(labels.cpu().numpy())\n",
    "        # Statistics\n",
    "        test_loss += loss.item() * inputs.size(0)\n",
    "        test_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "test_acc = test_corrects.float() / len(test_loader.dataset)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "cf = plot_confusion_matrix(all_test_labels, all_test_preds, return_fig=True)\n",
    "fig = cf.figure_\n",
    "plt.gca().set_title(\"ResNet End-to-End \")\n",
    "fig.tight_layout()\n",
    "fig.savefig(figures_folder_path + \"/resnet_end_to_end.pdf\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
